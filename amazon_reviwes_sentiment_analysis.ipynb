{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "148559a3-70c4-4850-8263-f4ca1b48387b",
   "metadata": {},
   "source": [
    "## Amazon Reviews Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcae45a-9803-4e62-a5a7-bc2baa73402b",
   "metadata": {},
   "source": [
    "# Check GPU Availability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "348791eb-c9a9-463c-8451-24a320ecf592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa6d33e-e359-474f-9a17-434958ab059e",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e5381b7-37db-4098-945e-7b0c45cbff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bz2\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import gensim\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, BatchNormalization, MaxPool1D, LSTM, Dropout, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15c406d-be82-463a-ac0e-be49695027bf",
   "metadata": {},
   "source": [
    "# Load and Preprocess Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb3f5f87-6680-4521-979c-ac17aaf257db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_and_texts(file):\n",
    "    labels = []\n",
    "    texts = []\n",
    "    for line in bz2.BZ2File(file):\n",
    "        x = line.decode(\"utf-8\")\n",
    "        labels.append(int(x[9]) - 1)\n",
    "        texts.append(x[10:].strip())\n",
    "    return np.array(labels), texts\n",
    "\n",
    "train_labels, train_texts = get_labels_and_texts('amazonreviews/train.ft.txt.bz2')\n",
    "test_labels, test_texts = get_labels_and_texts('amazonreviews/test.ft.txt.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aba5d937-619f-40af-ab5f-2f39f12d914c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d638af5d-eb9d-4077-b102-d25618efff75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00657880-f3b6-4f0b-b614-196a48a68631",
   "metadata": {},
   "source": [
    "# Text Cleaning Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90d5bae0-6051-434c-9bf4-8fb7dee7ee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(text):\n",
    "    text = text.lower()  \n",
    "    pattern_punc = r'[^A-Za-z\\s]'\n",
    "    text = re.sub(pattern_punc, '', text).strip()\n",
    "    return text \n",
    "\n",
    "train_texts_clean = [text_cleaning(text) for text in train_texts]\n",
    "test_texts_clean = [text_cleaning(text) for text in test_texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5a6b2d1-cafa-44ad-80b5-b3ddb0c8b29f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stuning even for the nongamer this sound track was beautiful it paints the senery in your mind so well i would recomend it even to people who hate vid game music i have played the game chrono cross but out of all of the games i have ever played it has the best music it backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras it would impress anyone who cares to listen'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts_clean[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f68a6e-b0dc-416d-a93d-f29d45719664",
   "metadata": {},
   "source": [
    "# Tokenization and Padding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d80bb9a0-2c9f-432f-9c59-f0f9e9983d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000  \n",
    "max_len = 100  \n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(train_texts_clean)\n",
    "\n",
    "X_train_seq = pad_sequences(tokenizer.texts_to_sequences(train_texts_clean), maxlen=max_len)\n",
    "X_test_seq = pad_sequences(tokenizer.texts_to_sequences(test_texts_clean), maxlen=max_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78346cb6-963e-4cb9-b3c8-d6b14fa2087b",
   "metadata": {},
   "source": [
    "# LSTM Model with Own Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e777755d-1516-4466-95b6-e887d4c9c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model():\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=max_words, output_dim=100, input_length=max_len, trainable=True),\n",
    "        LSTM(128, return_sequences=True),\n",
    "        LSTM(64),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18e69d8a-9d63-450c-8e5e-cb64c42f7352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM with Own Embedding\n",
      "Epoch 1/5\n",
      "28125/28125 [==============================] - 670s 23ms/step - loss: 0.2155 - accuracy: 0.9136 - val_loss: 0.1839 - val_accuracy: 0.9275\n",
      "Epoch 2/5\n",
      "28125/28125 [==============================] - 685s 24ms/step - loss: 0.1772 - accuracy: 0.9312 - val_loss: 0.1710 - val_accuracy: 0.9332\n",
      "Epoch 3/5\n",
      "28125/28125 [==============================] - 9861s 351ms/step - loss: 0.1650 - accuracy: 0.9365 - val_loss: 0.1658 - val_accuracy: 0.9354\n",
      "Epoch 4/5\n",
      "28125/28125 [==============================] - 701s 25ms/step - loss: 0.1578 - accuracy: 0.9397 - val_loss: 0.1636 - val_accuracy: 0.9366\n",
      "Epoch 5/5\n",
      "28125/28125 [==============================] - 736s 26ms/step - loss: 0.1525 - accuracy: 0.9421 - val_loss: 0.1625 - val_accuracy: 0.9371\n",
      "12500/12500 [==============================] - 131s 10ms/step - loss: 0.1625 - accuracy: 0.9371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1624835729598999, 0.9370599985122681]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training LSTM with Own Embedding\")\n",
    "model = build_lstm_model()\n",
    "model.fit(X_train_seq, train_labels, validation_data=(X_test_seq, test_labels), epochs=5, batch_size=128)\n",
    "model.evaluate(X_test_seq, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2b5107-a7d2-42ca-8bc5-2d90dc4cb61c",
   "metadata": {},
   "source": [
    "# Load GloVe Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f443508f-d6f6-4cc0-b301-2d52a4bd72c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embedding(glove_path , embedding_dim):\n",
    "    embedding_index = {}\n",
    "    with open(glove_path , encoding = 'utf-8') as f :\n",
    "        for line in f :\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coef = np.asarray(values[1:] , dtype = 'float64')\n",
    "            embedding_index[word] = coef\n",
    "    return embedding_index   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4789f5fc-833b-4b5c-a0e0-b06a2f6d154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = 'glove_path/glove.6B.100d.txt'\n",
    "embedding_dim = 100\n",
    "embedding_index = load_glove_embedding(glove_path , embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3238b923-295f-432a-9744-506b6da6ccb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.046539 ,  0.61966  ,  0.56647  , -0.46584  , -1.189    ,\n",
       "        0.44599  ,  0.066035 ,  0.3191   ,  0.14679  , -0.22119  ,\n",
       "        0.79239  ,  0.29905  ,  0.16073  ,  0.025324 ,  0.18678  ,\n",
       "       -0.31001  , -0.28108  ,  0.60515  , -1.0654   ,  0.52476  ,\n",
       "        0.064152 ,  1.0358   , -0.40779  , -0.38011  ,  0.30801  ,\n",
       "        0.59964  , -0.26991  , -0.76035  ,  0.94222  , -0.46919  ,\n",
       "       -0.18278  ,  0.90652  ,  0.79671  ,  0.24825  ,  0.25713  ,\n",
       "        0.6232   , -0.44768  ,  0.65357  ,  0.76902  , -0.51229  ,\n",
       "       -0.44333  , -0.21867  ,  0.3837   , -1.1483   , -0.94398  ,\n",
       "       -0.15062  ,  0.30012  , -0.57806  ,  0.20175  , -1.6591   ,\n",
       "       -0.079195 ,  0.026423 ,  0.22051  ,  0.99714  , -0.57539  ,\n",
       "       -2.7266   ,  0.31448  ,  0.70522  ,  1.4381   ,  0.99126  ,\n",
       "        0.13976  ,  1.3474   , -1.1753   ,  0.0039503,  1.0298   ,\n",
       "        0.064637 ,  0.90887  ,  0.82872  , -0.47003  , -0.10575  ,\n",
       "        0.5916   , -0.4221   ,  0.57331  , -0.54114  ,  0.10768  ,\n",
       "        0.39784  , -0.048744 ,  0.064596 , -0.61437  , -0.286    ,\n",
       "        0.5067   , -0.49758  , -0.8157   ,  0.16408  , -1.963    ,\n",
       "       -0.26693  , -0.37593  , -0.95847  , -0.8584   , -0.71577  ,\n",
       "       -0.32343  , -0.43121  ,  0.41392  ,  0.28374  , -0.70931  ,\n",
       "        0.15003  , -0.2154   , -0.37616  , -0.032502 ,  0.8062   ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_index['i']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fae605-7298-42f1-826e-ebf0306d8cd1",
   "metadata": {},
   "source": [
    "# Create Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c82f8ac-fa8e-4f9f-80ee-367f2bf4c66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 10000\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "embedding_matrix = np.zeros((max_words , embedding_dim))\n",
    "\n",
    "for word , i in word_index.items():\n",
    "    if i < max_words:\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        if embedding_vector is not None :\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "        else :\n",
    "            embedding_matrix[i] = np.random.rand(embedding_dim)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e041f25f-43fc-4b06-9339-1c4d84448629",
   "metadata": {},
   "source": [
    "# LSTM Model with GloVe Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cd3e18f-a564-4a38-bd4f-76df0ef27bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_with_glove():\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=max_words, \n",
    "                  output_dim=embedding_dim, \n",
    "                  input_length=max_len, \n",
    "                  weights=[embedding_matrix],  \n",
    "                  trainable=False), \n",
    "        LSTM(128, return_sequences=True),\n",
    "        LSTM(64),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb22433e-9fee-4e71-9ea7-98d149cd49f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 100)          1000000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100, 128)          117248    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,166,721\n",
      "Trainable params: 166,721\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_lstm_with_glove()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98156c8c-2bab-4267-90f8-87e908637456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM with GLOVE Embedding\n",
      "Epoch 1/5\n",
      "28125/28125 [==============================] - 668s 23ms/step - loss: 0.2328 - accuracy: 0.9045 - val_loss: 0.1958 - val_accuracy: 0.9211\n",
      "Epoch 2/5\n",
      "28125/28125 [==============================] - 651s 23ms/step - loss: 0.1880 - accuracy: 0.9262 - val_loss: 0.1813 - val_accuracy: 0.9278\n",
      "Epoch 3/5\n",
      "28125/28125 [==============================] - 679s 24ms/step - loss: 0.1768 - accuracy: 0.9312 - val_loss: 0.1779 - val_accuracy: 0.9300\n",
      "Epoch 4/5\n",
      "28125/28125 [==============================] - 648s 23ms/step - loss: 0.1705 - accuracy: 0.9340 - val_loss: 0.1768 - val_accuracy: 0.9318\n",
      "Epoch 5/5\n",
      "28125/28125 [==============================] - 647s 23ms/step - loss: 0.1660 - accuracy: 0.9360 - val_loss: 0.1739 - val_accuracy: 0.9327\n",
      "12500/12500 [==============================] - 121s 10ms/step - loss: 0.1739 - accuracy: 0.9327\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17392566800117493, 0.9326574802398682]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training LSTM with GLOVE Embedding\")\n",
    "model.fit(X_train_seq, train_labels, validation_data=(X_test_seq, test_labels), epochs=5, batch_size=128)\n",
    "model.evaluate(X_test_seq, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3681b1-efa6-49a4-b0cf-b7404a80fef0",
   "metadata": {},
   "source": [
    "# Hybrid CNN-LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8d06bd0-afbf-453a-b0bd-0e9fb922338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hybrid_model():\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=max_words, output_dim=100, input_length=max_len, trainable=True),  \n",
    "        \n",
    "        Conv1D(64, 3, activation='relu', padding='same'),  \n",
    "        BatchNormalization(),\n",
    "        MaxPool1D(2),\n",
    "\n",
    "        Conv1D(64, 5, activation='relu', padding='same'),  \n",
    "        BatchNormalization(),\n",
    "        MaxPool1D(2),\n",
    "\n",
    "        LSTM(128, return_sequences=True),  \n",
    "        LSTM(64),  \n",
    "\n",
    "        Dropout(0.5),  \n",
    "        Dense(1, activation='sigmoid')  # طبقة الإخراج للتصنيف الثنائي\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c51ee21-0765-4e3d-8080-f0c402cb7739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training hybrid_model\n",
      "Epoch 1/5\n",
      "28125/28125 [==============================] - 642s 23ms/step - loss: 0.1627 - accuracy: 0.9376 - val_loss: 0.1722 - val_accuracy: 0.9334\n",
      "Epoch 2/5\n",
      "28125/28125 [==============================] - 644s 23ms/step - loss: 0.1599 - accuracy: 0.9387 - val_loss: 0.1710 - val_accuracy: 0.9333\n",
      "Epoch 3/5\n",
      "28125/28125 [==============================] - 642s 23ms/step - loss: 0.1577 - accuracy: 0.9397 - val_loss: 0.1706 - val_accuracy: 0.9333\n",
      "Epoch 4/5\n",
      "28125/28125 [==============================] - 646s 23ms/step - loss: 0.1558 - accuracy: 0.9405 - val_loss: 0.1779 - val_accuracy: 0.9302\n",
      "Epoch 5/5\n",
      "28125/28125 [==============================] - 655s 23ms/step - loss: 0.1542 - accuracy: 0.9411 - val_loss: 0.1702 - val_accuracy: 0.9341\n",
      "12500/12500 [==============================] - 118s 9ms/step - loss: 0.1702 - accuracy: 0.9341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17023691534996033, 0.9340999722480774]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training hybrid_model\" )\n",
    "model.fit(X_train_seq, train_labels, validation_data=(X_test_seq, test_labels), epochs=5, batch_size=128)\n",
    "model.evaluate(X_test_seq, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4c422d-2c72-46d5-a672-774d1cfe5aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
